{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 机器学习笔记2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------\n",
    "本次任务的主要学习知识点是线性回归。该笔记将着重从以下方面对线性回归内容进行说明和整理："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 线性回归的原理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 线性回归损失函数、代价函数、目标函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 优化方法（梯度下降法、牛顿法、拟牛顿法等）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 线性回归的评估指标"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* SKlearn参数详解"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 线性模型回顾"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "线性回归来自于线性模型，所谓的线性模型就是：某变量X通过d个属性来描述，要求生成一个通过属性的线性组合来进行预测的函数法f(x)。其表达书如下："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$X=(x_1,x_2,...,x_d)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$f(X)=w_1x_1+w_2x_2+...+w_dx_d+b$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一般地，通过向量可表示为："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$f(X)=w^TX+b$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其中$w=(w_1,w_2,...,w_d)$，当w和b学习到之后，模型就确定下来了"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "线性模型有很多种，包含常见的线性回归、对数几率回归、线性判别分析、多分类学习等。这里只记录线性回归的知识点。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.线性回归的原理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------\n",
    "线性回归的推导过程可以在周志华老师的机器学习一书中具体看到，这里就做简要的总结，其基本的公式如下："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在一般的情况下，给定数据集$D={(x_1,y_1),(x_2,y_2),...,(x_m,y_m)}$，其中$x_i=(x_i1,x_i2,...,x_id)，y_i∈R$。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "此时需要学习的函数可以表示为：$f(x_i)=w^Tx_i+b$，使得$f(x_i)≈y_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "相应地，这里需要估计出w和b的值，才能确定出回归函数的值。为了讨论方便，将b吸收到w中，组成增广矩阵的形式，即$w^*=(w,b)$，相应的就把数据集D变为了$m*(d+1)$的矩阵X，可表示为："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\mathbf{X}=\\left(\\begin{array}{ccccc}\n",
    "{x_{11}} & {x_{12}} & {\\dots} & {x_{1 d}} & {1} \\\\\n",
    "{x_{21}} & {x_{22}} & {\\dots} & {x_{2 d}} & {1} \\\\\n",
    "{\\vdots} & {\\vdots} & {\\ddots} & {\\vdots} & {\\vdots} \\\\\n",
    "{x_{m 1}} & {x_{m 2}} & {\\dots} & {x_{m d}} & {1}\n",
    "\\end{array}\\right)=\\left(\\begin{array}{cc}\n",
    "{x_{1}^{\\mathrm{T}}} & {1} \\\\\n",
    "{x_{2}^{\\mathrm{T}}} & {1} \\\\\n",
    "{\\vdots} & {\\vdots} \\\\\n",
    "{x_{m}^{\\mathrm{T}}} & {1}\n",
    "\\end{array}\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "相应地，把标记也写为向量形式，即：$y=(y_1,y_2,...,y_m)$，于是有：$\\hat{\\boldsymbol{w}}^{*}=\\underset{\\hat{w}}{\\arg \\min }(\\boldsymbol{y}-\\mathbf{X} \\hat{\\boldsymbol{w}})^{\\mathrm{T}}(\\boldsymbol{y}-\\mathbf{X} \\hat{\\boldsymbol{w}})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过矩阵求解，最终学习到的线性回归模型为：$f\\left(\\hat{\\boldsymbol{x}}_{i}\\right)=\\hat{\\boldsymbol{x}}_{i}^{\\mathrm{T}}\\left(\\mathbf{X}^{\\mathrm{T}} \\mathbf{X}\\right)^{-1} \\mathbf{X}^{\\mathrm{T}} \\boldsymbol{y}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这其中需要注意的知识点是：矩阵$X^TX$是满秩矩阵，但是实际生活中，并不都是满足这一条件，因此会存在多个解满足上述条件，使得均方误差最小。这时候究竟是选择哪个解作为输出，就需要做一些处理，比如正则化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#生成数据\n",
    "import numpy as np\n",
    "#生成随机数\n",
    "np.random.seed(1234)\n",
    "x = np.random.rand(500,3)\n",
    "# 构建映射关系，模拟真实的数据待预测值,映射关系为y = 4.2 + 5.7*x1 + 10.8*x2，可自行设置值进行尝试\n",
    "y = x.dot(np.array([4.2,5.7,10.8]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "估计的参数值为：[ 4.2  5.7 10.8]\n",
      "R2:1.0\n",
      "预测值为: [85.2]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# 调用模型\n",
    "lr = LinearRegression(fit_intercept=True)\n",
    "# 训练模型\n",
    "lr.fit(x,y)\n",
    "print(\"估计的参数值为：%s\" %(lr.coef_))\n",
    "# 计算R平方\n",
    "print('R2:%s' %(lr.score(x,y)))\n",
    "# 任意设定变量，预测目标值\n",
    "x_test = np.array([2,4,5]).reshape(1,-1)\n",
    "y_hat = lr.predict(x_test)\n",
    "print(\"预测值为: %s\" %(y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-6-9626c835e784>, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-6-9626c835e784>\"\u001b[1;36m, line \u001b[1;32m7\u001b[0m\n\u001b[1;33m    self.w =\u001b[0m\n\u001b[1;37m             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class LR_LS():\n",
    "    def __init__(self):\n",
    "        self.w = None      \n",
    "    def fit(self, X, y):\n",
    "        # 最小二乘法矩阵求解\n",
    "        #============================= show me your code =======================\n",
    "        self.w = \n",
    "        #============================= show me your code =======================\n",
    "    def predict(self, X):\n",
    "        # 用已经拟合的参数值预测新自变量\n",
    "        #============================= show me your code =======================\n",
    "        y_pred = \n",
    "        #============================= show me your code =======================\n",
    "        return y_pred\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    lr_ls = LR_LS()\n",
    "    lr_ls.fit(x,y)\n",
    "    print(\"估计的参数值：%s\" %(lr_ls.w))\n",
    "    x_test = np.array([2,4,5]).reshape(1,-1)\n",
    "    print(\"预测值为: %s\" %(lr_ls.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
